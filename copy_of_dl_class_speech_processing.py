# -*- coding: utf-8 -*-
"""Copy of DL_Class_Speech_Processing.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1nih-haMiWtj-35zTaoE8U9rZW8KyyU0Y

# Introduction to Audio Processing in Python
"""

!pip install Soundfile

"""#Read/Write Functions"""

from google.colab import drive
drive.mount('/content/drive')

!ls /content/drive/MyDrive/AudioFile_Class/

import soundfile as sf

data, samplerate = sf.read('/content/drive/MyDrive/AudioFile_Class/town-10169.mp3')
sf.write('town.wav', data, samplerate)
print(samplerate)

!ls

print(data)

import soundfile as sf
sf.available_formats()

"""\

# Open File and Close File
"""

from soundfile import SoundFile
myfile = SoundFile('town.wav')
# do something with myfile
print(myfile.buffer_read)
myfile.close()

from soundfile import SoundFile
myfile = SoundFile('town.wav')
myfile.channels, myfile.format, myfile.format_info, myfile.name, myfile.samplerate, myfile.sections, myfile.frames

myfile.close()

import io
import soundfile as sf
from urllib.request import urlopen

url = "http://tinyurl.com/shepard-risset"
data, samplerate = sf.read(io.BytesIO(urlopen(url).read()))
samplerate

"""# Playing Sound"""

from IPython.display import Audio
wn = Audio('/content/drive/MyDrive/AudioFile_Class/town-10169.mp3', autoplay=True)
display(wn)

!apt-get install ffmpeg libavcodec-extra
!pip install pydub

# import required modules
from pydub import AudioSegment
from pydub.playback import play

# for playing wav file
song = AudioSegment.from_wav("town.wav")
print('playing sound using  pydub')
display(song)

'''
from pydub import AudioSegment

song = AudioSegment.from_wav("never_gonna_give_you_up.wav")
song = AudioSegment.from_mp3("never_gonna_give_you_up.mp3")
ogg_version = AudioSegment.from_ogg("never_gonna_give_you_up.ogg")
flv_version = AudioSegment.from_flv("never_gonna_give_you_up.flv")

mp4_version = AudioSegment.from_file("never_gonna_give_you_up.mp4", "mp4")
wma_version = AudioSegment.from_file("never_gonna_give_you_up.wma", "wma")
aac_version = AudioSegment.from_file("never_gonna_give_you_up.aiff", "aac")

sound = AudioSegment.from_file("mysound.wav", format="wav")

'''

"""## Slice audio:"""

# pydub does things in milliseconds
ten_seconds = 10 * 1000

first_10_seconds = song[:ten_seconds]

last_5_seconds = song[-5000:]

display(first_10_seconds)

display(last_5_seconds)

"""## Audio - Volumn increase / Decrease








"""

# boost volume by 16dB
beginning = first_10_seconds + 16

# reduce volume by 6dB
end = last_5_seconds - 6

display(first_10_seconds)

display(beginning)

display(end)

"""# Concatenate audio (add one file to the end of another)


"""

without_the_middle = beginning + end
display(without_the_middle)

without_the_middle.duration_seconds

"""AudioSegments are immutable


"""

# song is not modified
backwards = song.reverse()
display(backwards)

display(song)

"""##Crossfade (again, beginning and end are not modified)


"""

# 1.5 second crossfade
with_style = beginning.append(end, crossfade=1500)
display(with_style)

"""#Repeat"""

# repeat the clip twice
do_it_over = with_style * 2
display(do_it_over)

"""## Fade (note that you can chain operations because everything returns an AudioSegment)


"""

# 2 sec fade in, 3 sec fade out
awesome = do_it_over.fade_in(2000).fade_out(3000)
display(awesome)

"""#Save the results (again whatever ffmpeg supports)


"""

awesome.export("mashup.mp3", format="mp3")
display(awesome)

"""#Save the results with tags (metadata)


"""

awesome.export("mashup.mp3", format="mp3", tags={'artist': 'Various artists', 'album': 'Best of 2011', 'comments': 'This album is awesome!'})

song = AudioSegment.from_mp3("mashup.mp3")
display(song)

"""## Librosa"""

!pip install Librosa

import librosa
audio_data = 'town.wav'
x , sr = librosa.load(audio_data)
print(type(x), type(sr))
print(x, sr)

"""## Sampling Audio"""

from IPython.display import Audio
Audio(data=x, rate=sr)

# Automatically resample to a desired fs
y, sr = librosa.load('town.wav', sr=44100)

print('New Sampling Rante', sr)

Audio(data=y, rate=sr)

# Automatically resample to a desired fs
z, sr = librosa.load('town.wav', sr=16000)

Audio(data=z, rate=sr)

"""# Disable resampling"""

z, sr = librosa.load('town.wav', sr=None)
Audio(data=z, rate=sr)

"""#Visualizing Audio:

# WavePlot

- We can plot the audio array using librosa.display.waveplot
"""

z, sr = librosa.load('town.wav', sr=None)

type(z), z.shape, z, len(z)

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
import matplotlib.pyplot as plt
import librosa.display
plt.figure(figsize=(14, 5))
librosa.display.waveshow(z, sr=sr)

"""https://www.kdnuggets.com/2020/02/audio-data-analysis-deep-learning-python-part-1.html

## Spectrogram

- A spectrogram is a visual way of representing the signal strength, or “loudness”, of a signal over time at various frequencies present in a particular waveform.

- Not only can one see whether there is more or less energy at, for example, 2 Hz vs 10 Hz, but one can also see how energy levels vary over time.

- A spectrogram is usually depicted as a heat map, i.e., as an image with the intensity shown by varying the color or brightness.
"""

x, sr = librosa.load('town.wav', sr=None)
X = librosa.stft(x)
Xdb = librosa.amplitude_to_db(abs(X))
plt.figure(figsize=(14, 5))
librosa.display.specshow(Xdb, sr=sr, x_axis='time', y_axis='hz')
plt.colorbar()

librosa.display.specshow(Xdb, sr=sr, x_axis='time', y_axis='log')
plt.colorbar()

"""# Playing a synthetic sound

"""

sr = 22050

y_sweep = librosa.chirp(fmin=librosa.note_to_hz('C3'),
                        fmax=librosa.note_to_hz('C5'),
                        sr=sr,
                        duration=5)

Audio(data=y_sweep, rate=sr)

import soundfile as sf

import numpy as np
sr = 22050 # sample rate
T = 5.0    # seconds
t = np.linspace(0, T, int(T*sr), endpoint=False) # time variable
x = 0.5*np.sin(2*np.pi*220*t)# pure sine wave at 220 Hz

#Saving the audio
#librosa.output.write_wav('tone_220.wav', x, sr)

sf.write('tone_220.wav', x, sr, 'PCM_24')

#Playing the audio
Audio(x, rate=sr) # load a NumPy array

"""#Feature extraction from Audio signal

- Every audio signal consists of many features. However, we must extract the characteristics that are relevant to the problem we are trying to solve. The process of extracting features to use them for analysis is called feature extraction. Let us study a few of the features in detail.

- The spectral features (frequency-based features), which are obtained by converting the time-based signal into the frequency domain using the Fourier Transform, like fundamental frequency, frequency components, spectral centroid, spectral flux, spectral density, spectral roll-off, etc.

- spectral moments (centroid, bandwidth, skewness, kurtosis) and other spectral statistics.

### 1. Spectral Centroid

> The spectral centroid indicates at which frequency the energy of a spectrum is centered upon or in other words It indicates where the ” center of mass” for a sound is located. This is like a weighted mean



> librosa.feature.spectral_centroid computes the spectral centroid for each frame in a signal:


"""

x, sr = librosa.load('town.wav', sr=44100)

import sklearn
spectral_centroids = librosa.feature.spectral_centroid(y=x, sr=sr)[0]
spectral_centroids.shape

spectral_centroids

# Computing the time variable for visualization
plt.figure(figsize=(12, 4))
frames = range(len(spectral_centroids))
t = librosa.frames_to_time(frames)

t

from sklearn.preprocessing import MinMaxScaler
# Normalising the spectral centroid for visualisation
def normalize(x, axis=0):
    return sklearn.preprocessing.minmax_scale(x,axis=axis)

#Plotting the Spectral Centroid along the waveform
librosa.display.waveshow(x, sr=sr, alpha=0.4)
times = librosa.times_like(spectral_centroids)
plt.plot(t, normalize(spectral_centroids), color='b')

spectral_centroids = librosa.feature.spectral_centroid(y=x+0.01, sr=sr)[0]
librosa.display.waveshow(x, sr=sr, alpha=0.4)
plt.plot(t, normalize(spectral_centroids), color='r') # normalize for visualization purposes

"""# 2. Spectral Rolloff

- Spectral rolloff is the frequency below which a specified percentage of the total spectral energy, e.g. 85%, lies.

> It is a measure of the shape of the signal.

> It represents the frequency at which high frequencies decline to 0.

> To obtain it, we have to calculate the fraction of bins in the power spectrum where 85% of its power is at lower frequencies.

librosa.feature.spectral_rolloff computes the rolloff frequency for each frame in a signal:


"""

spectral_rolloff = librosa.feature.spectral_rolloff(y=x+0.01, sr=sr)[0]
plt.figure(figsize=(12, 4))
librosa.display.waveshow(x, sr=sr, alpha=0.4)
plt.plot(t, normalize(spectral_rolloff), color='r')

"""### 3. Spectral Bandwidth

The spectral bandwidth is defined as the width of the band of light at one-half the peak maximum (or full width at half maximum [FWHM]) and is represented by the two vertical red lines and λSB on the wavelength axis.


"""

spectral_bandwidth_2 = librosa.feature.spectral_bandwidth(y=x+0.01, sr=sr)[0]
spectral_bandwidth_3 = librosa.feature.spectral_bandwidth(y=x+0.01, sr=sr, p=3)[0]
spectral_bandwidth_4 = librosa.feature.spectral_bandwidth(y=x+0.01, sr=sr, p=4)[0]
plt.figure(figsize=(15, 9))
librosa.display.waveshow(x, sr=sr, alpha=0.4)
plt.plot(t, normalize(spectral_bandwidth_2), color='r')
plt.plot(t, normalize(spectral_bandwidth_3), color='g')
plt.plot(t, normalize(spectral_bandwidth_4), color='y')
plt.legend(('p = 2', 'p = 3', 'p = 4'))

"""## 4. Zero-Crossing Rate

A very simple way for measuring the smoothness of a signal is to calculate the number of zero-crossing within a segment of that signal. A voice signal oscillates slowly — for example, a 100 Hz signal will cross zero 100 per second — whereas an unvoiced fricative can have 3000 zero crossings per second.


"""

#Plot the signal:
plt.figure(figsize=(14, 5))
librosa.display.waveshow(x, sr=sr)
# Zooming in
n0 = 9000
n1 = 9100
plt.figure(figsize=(14, 5))
plt.plot(x[n0:n1])
plt.grid()

n0 = 9000
n1 = 9100
plt.figure(figsize=(14, 5))
plt.plot(x[n0:n1])
plt.grid()

zero_crossings = librosa.zero_crossings(x[n0:n1], pad=False)
print(sum(zero_crossings))

"""## 4A. Spectral Contrast

- Spectral contrast considers the spectral peak, the spectral valley, and their difference in each frequency subband.
"""

y, sr = librosa.load('town.wav', sr=44100)
spectral_contrast = librosa.feature.spectral_contrast(y=x, sr=sr)
spectral_contrast.shape

plt.imshow(normalize(spectral_contrast, axis=1), aspect='auto', origin='lower', cmap='coolwarm')

"""## 5. Mel-Frequency Cepstral Coefficients(MFCCs)

The Mel frequency cepstral coefficients (MFCCs) of a signal are a small set of features (usually about 10–20) which concisely describe the overall shape of a spectral envelope. It models the characteristics of the human voice.


"""

x, sr = librosa.load('town.wav', sr=None)

mfccs = librosa.feature.mfcc(y=x, sr=sr)
print(mfccs.shape)
(20, 97)
#Displaying  the MFCCs:
plt.figure(figsize=(15, 7))
librosa.display.specshow(mfccs, sr=sr, x_axis='time')

"""##6. Chroma feature

A chroma feature or vector is typically a 12-element feature vector indicating how much energy of each pitch class, {C, C#, D, D#, E, …, B}, is present in the signal. In short, It provides a robust way to describe a similarity measure between music pieces.


"""

x, sr = librosa.load('town.wav', sr=None)

chromagram = librosa.feature.chroma_stft(y=x, sr=sr)
plt.figure(figsize=(15, 5))
librosa.display.specshow(chromagram, x_axis='time', y_axis='chroma', cmap='coolwarm')

"""# Several - Insights"""

#Compute a chromagram from a waveform or power spectrogram.
librosa.feature.chroma_stft(y=y, sr=sr)

#Use an energy (magnitude) spectrum instead of power spectrogram

S = np.abs(librosa.stft(y))
chroma = librosa.feature.chroma_stft(S=S, sr=sr)

import matplotlib.pyplot as plt
fig, ax = plt.subplots(nrows=2, sharex=True)
img = librosa.display.specshow(librosa.amplitude_to_db(S, ref=np.max),
                               y_axis='log', x_axis='time', ax=ax[0])
fig.colorbar(img, ax=[ax[0]])
ax[0].label_outer()
img = librosa.display.specshow(chroma, y_axis='chroma', x_axis='time', ax=ax[1])
fig.colorbar(img, ax=[ax[1]])

#Use a pre-computed power spectrogram with a larger frame

S = np.abs(librosa.stft(y, n_fft=4096))**2
chroma = librosa.feature.chroma_stft(S=S, sr=sr)

import matplotlib.pyplot as plt
fig, ax = plt.subplots(nrows=2, sharex=True)
img = librosa.display.specshow(librosa.amplitude_to_db(S, ref=np.max),
                               y_axis='log', x_axis='time', ax=ax[0])
fig.colorbar(img, ax=[ax[0]])
ax[0].label_outer()
img = librosa.display.specshow(chroma, y_axis='chroma', x_axis='time', ax=ax[1])
fig.colorbar(img, ax=[ax[1]])

"""## Constant-Q chromagram"""

y, sr = librosa.load('town.wav', sr=None)

chroma_stft = librosa.feature.chroma_stft(y=y, sr=sr,
                                          n_chroma=12, n_fft=4096)
chroma_cq = librosa.feature.chroma_cqt(y=y, sr=sr)

import matplotlib.pyplot as plt
fig, ax = plt.subplots(nrows=2, sharex=True, sharey=True)
librosa.display.specshow(chroma_stft, y_axis='chroma', x_axis='time', ax=ax[0])
ax[0].set(title='chroma_stft')
ax[0].label_outer()
img = librosa.display.specshow(chroma_cq, y_axis='chroma', x_axis='time', ax=ax[1])
ax[1].set(title='chroma_cqt')
fig.colorbar(img, ax=ax)

"""#Computes the chroma variant “Chroma Energy Normalized” (CENS)

"""

y, sr = librosa.load('town.wav', sr=None)

chroma_cens = librosa.feature.chroma_cens(y=y, sr=sr)
chroma_cq = librosa.feature.chroma_cqt(y=y, sr=sr)

import matplotlib.pyplot as plt
fig, ax = plt.subplots(nrows=2, sharex=True, sharey=True)
img = librosa.display.specshow(chroma_cq, y_axis='chroma', x_axis='time', ax=ax[0])
ax[0].set(title='chroma_cq')
ax[0].label_outer()
librosa.display.specshow(chroma_cens, y_axis='chroma', x_axis='time', ax=ax[1])
ax[1].set(title='chroma_cens')
fig.colorbar(img, ax=ax)

"""#Variable-Q chromagram"""

y, sr = librosa.load('town.wav', sr=None)

n_bins = 36
chroma_cq = librosa.feature.chroma_cqt(y=y, sr=sr, n_chroma=n_bins)
chroma_vq = librosa.feature.chroma_vqt(y=y, sr=sr,
                                       intervals='ji5',
                                       bins_per_octave=n_bins)

import matplotlib.pyplot as plt
fig, ax = plt.subplots(nrows=2, sharex=True)
librosa.display.specshow(chroma_cq, y_axis='chroma', x_axis='time',
                         ax=ax[0], bins_per_octave=n_bins)
ax[0].set(ylabel='chroma_cqt')
ax[0].label_outer()
img = librosa.display.specshow(chroma_vq, y_axis='chroma_fjs', x_axis='time',
                               ax=ax[1], bins_per_octave=n_bins,
                               intervals='ji5')
ax[1].set(ylabel='chroma_vqt')
fig.colorbar(img, ax=ax)

"""#Compute a mel-scaled spectrogram."""

S = librosa.feature.melspectrogram(y=y, sr=sr)

D = np.abs(librosa.stft(y))**2
S1 = librosa.feature.melspectrogram(S=D, sr=sr)

# Passing through arguments to the Mel filters
S2 = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128,
                                    fmax=8000)

import matplotlib.pyplot as plt
fig, ax = plt.subplots()
S_dB = librosa.power_to_db(S, ref=np.max)
img = librosa.display.specshow(S_dB, x_axis='time',
                         y_axis='mel', sr=sr,
                         fmax=8000, ax=ax)
fig.colorbar(img, ax=ax, format='%+2.0f dB')
ax.set(title='Mel-frequency spectrogram')

import matplotlib.pyplot as plt
fig, ax = plt.subplots()
S_dB = librosa.power_to_db(S1, ref=np.max)
img = librosa.display.specshow(S_dB, x_axis='time',
                         y_axis='mel', sr=sr,
                         fmax=8000, ax=ax)
fig.colorbar(img, ax=ax, format='%+2.0f dB')
ax.set(title='Mel-frequency spectrogram')

import matplotlib.pyplot as plt
fig, ax = plt.subplots()
S_dB = librosa.power_to_db(S2, ref=np.max)
img = librosa.display.specshow(S_dB, x_axis='time',
                         y_axis='mel', sr=sr,
                         fmax=8000, ax=ax)
fig.colorbar(img, ax=ax, format='%+2.0f dB')
ax.set(title='Mel-frequency spectrogram')

"""#Mel-frequency cepstral coefficients (MFCCs)"""

y, sr = librosa.load('town.wav', sr=None)

mfccs= librosa.feature.mfcc(y=y, sr=sr)

mfccs1 = librosa.feature.mfcc(y=y, sr=sr, hop_length=1024, htk=True)

S = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128,
                                   fmax=8000)
mfccs2 = librosa.feature.mfcc(S=librosa.power_to_db(S))

mfccs3 = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=40)

import matplotlib.pyplot as plt
fig, ax = plt.subplots(nrows=2, sharex=True)
img = librosa.display.specshow(librosa.power_to_db(S, ref=np.max),
                               x_axis='time', y_axis='mel', fmax=8000,
                               ax=ax[0])
fig.colorbar(img, ax=[ax[0]])
ax[0].set(title='Mel spectrogram')
ax[0].label_outer()
img = librosa.display.specshow(mfccs, x_axis='time', ax=ax[1])
fig.colorbar(img, ax=[ax[1]])
ax[1].set(title='MFCC')

import matplotlib.pyplot as plt
fig, ax = plt.subplots(nrows=2, sharex=True)
img = librosa.display.specshow(librosa.power_to_db(S, ref=np.max),
                               x_axis='time', y_axis='mel', fmax=8000,
                               ax=ax[0])
fig.colorbar(img, ax=[ax[0]])
ax[0].set(title='Mel spectrogram')
ax[0].label_outer()
img = librosa.display.specshow(mfccs1, x_axis='time', ax=ax[1])
fig.colorbar(img, ax=[ax[1]])
ax[1].set(title='MFCC')

import matplotlib.pyplot as plt
fig, ax = plt.subplots(nrows=2, sharex=True)
img = librosa.display.specshow(librosa.power_to_db(S, ref=np.max),
                               x_axis='time', y_axis='mel', fmax=8000,
                               ax=ax[0])
fig.colorbar(img, ax=[ax[0]])
ax[0].set(title='Mel spectrogram')
ax[0].label_outer()
img = librosa.display.specshow(mfccs2, x_axis='time', ax=ax[1])
fig.colorbar(img, ax=[ax[1]])
ax[1].set(title='MFCC')

import matplotlib.pyplot as plt
fig, ax = plt.subplots(nrows=2, sharex=True)
img = librosa.display.specshow(librosa.power_to_db(S, ref=np.max),
                               x_axis='time', y_axis='mel', fmax=8000,
                               ax=ax[0])
fig.colorbar(img, ax=[ax[0]])
ax[0].set(title='Mel spectrogram')
ax[0].label_outer()
img = librosa.display.specshow(mfccs3, x_axis='time', ax=ax[1])
fig.colorbar(img, ax=[ax[1]])
ax[1].set(title='MFCC')

"""# Compute root-mean-square (RMS) value for each frame, either from the audio samples y or from a spectrogram S.


"""

y, sr = librosa.load('town.wav', sr=None)

rms_1 = librosa.feature.rms(y=y)

S, phase = librosa.magphase(librosa.stft(y))
rms_2 = librosa.feature.rms(S=S)

import matplotlib.pyplot as plt
fig, ax = plt.subplots(nrows=2, sharex=True)
times = librosa.times_like(rms_1)
ax[0].semilogy(times, rms_1[0], label='RMS Energy')
ax[0].set(xticks=[])
ax[0].legend()
ax[0].label_outer()
librosa.display.specshow(librosa.amplitude_to_db(S, ref=np.max),
                         y_axis='log', x_axis='time', ax=ax[1])
ax[1].set(title='log Power spectrogram')

import matplotlib.pyplot as plt
fig, ax = plt.subplots(nrows=2, sharex=True)
times = librosa.times_like(rms_2)
ax[0].semilogy(times, rms_2[0], label='RMS Energy')
ax[0].set(xticks=[])
ax[0].legend()
ax[0].label_outer()
librosa.display.specshow(librosa.amplitude_to_db(S, ref=np.max),
                         y_axis='log', x_axis='time', ax=ax[1])
ax[1].set(title='log Power spectrogram')

"""#Compute the spectral centroid.


"""

!pip install librosa

import librosa
import numpy as np
from IPython.display import Audio
import matplotlib.pyplot as plt

y, sr = librosa.load(librosa.ex('trumpet'))
cent = librosa.feature.spectral_centroid(y=y, sr=sr)

S, phase = librosa.magphase(librosa.stft(y=y))
librosa.feature.spectral_centroid(S=S)

import matplotlib.pyplot as plt
times = librosa.times_like(cent)
fig, ax = plt.subplots()
librosa.display.specshow(librosa.amplitude_to_db(S, ref=np.max),
                         y_axis='log', x_axis='time', ax=ax)
ax.plot(times, cent.T, label='Spectral centroid', color='w')
ax.legend(loc='upper right')
ax.set(title='log Power spectrogram')

y, sr = librosa.load(librosa.ex('trumpet'))
spec_bw = librosa.feature.spectral_bandwidth(y=y, sr=sr)

S, phase = librosa.magphase(librosa.stft(y=y))
librosa.feature.spectral_bandwidth(S=S)

import matplotlib.pyplot as plt
fig, ax = plt.subplots(nrows=2, sharex=True)
times = librosa.times_like(spec_bw)
centroid = librosa.feature.spectral_centroid(S=S)
ax[0].semilogy(times, spec_bw[0], label='Spectral bandwidth')
ax[0].set(ylabel='Hz', xticks=[], xlim=[times.min(), times.max()])
ax[0].legend()
ax[0].label_outer()
librosa.display.specshow(librosa.amplitude_to_db(S, ref=np.max),
                         y_axis='log', x_axis='time', ax=ax[1])
ax[1].set(title='log Power spectrogram')
ax[1].fill_between(times, np.maximum(0, centroid[0] - spec_bw[0]),
                np.minimum(centroid[0] + spec_bw[0], sr/2),
                alpha=0.5, label='Centroid +- bandwidth')
ax[1].plot(times, centroid[0], label='Spectral centroid', color='w')
ax[1].legend(loc='lower right')

y, sr = librosa.load(librosa.ex('trumpet'))
S = np.abs(librosa.stft(y))
contrast = librosa.feature.spectral_contrast(S=S, sr=sr)

import matplotlib.pyplot as plt
fig, ax = plt.subplots(nrows=2, sharex=True)
img1 = librosa.display.specshow(librosa.amplitude_to_db(S,
                                                 ref=np.max),
                         y_axis='log', x_axis='time', ax=ax[0])
fig.colorbar(img1, ax=[ax[0]], format='%+2.0f dB')
ax[0].set(title='Power spectrogram')
ax[0].label_outer()
img2 = librosa.display.specshow(contrast, x_axis='time', ax=ax[1])
fig.colorbar(img2, ax=[ax[1]])
ax[1].set(ylabel='Frequency bands', title='Spectral contrast')

"""#Dynamic programming beat tracker."""

y, sr = librosa.load('town.wav',sr=None)
tempo, beats = librosa.beat.beat_track(y=y, sr=sr)

tempo

beats

librosa.frames_to_time(beats, sr=sr)

"""Track beats using a pre-computed onset envelope"""

onset_env = librosa.onset.onset_strength(y=y, sr=sr,
                                         aggregate=np.median)
tempo, beats = librosa.beat.beat_track(onset_envelope=onset_env,
                                       sr=sr)

import matplotlib.pyplot as plt
hop_length = 1024
fig, ax = plt.subplots(nrows=2, sharex=True)
times = librosa.times_like(onset_env, sr=sr, hop_length=hop_length)
M = librosa.feature.melspectrogram(y=y, sr=sr, hop_length=hop_length)
librosa.display.specshow(librosa.power_to_db(M, ref=np.max),
                         y_axis='mel', x_axis='time', hop_length=hop_length,
                         ax=ax[0])
ax[0].label_outer()
ax[0].set(title='Mel spectrogram')
ax[1].plot(times, librosa.util.normalize(onset_env),
         label='Onset strength')
ax[1].vlines(times[beats], 0, 1, alpha=0.5, color='r',
           linestyle='--', label='Beats')
ax[1].legend()

"""## Predominant local pulse (PLP) estimation."""

import librosa
import numpy as np

y, sr = librosa.load(librosa.ex('brahms'))
onset_env = librosa.onset.onset_strength(y=y, sr=sr)
pulse = librosa.beat.plp(onset_envelope=onset_env, sr=sr)
# Or compute pulse with an alternate prior, like log-normal
import scipy.stats
prior = scipy.stats.lognorm(loc=np.log(120), scale=120, s=1)
pulse_lognorm = librosa.beat.plp(onset_envelope=onset_env, sr=sr,
                                 prior=prior)
melspec = librosa.feature.melspectrogram(y=y, sr=sr)

import matplotlib.pyplot as plt
fig, ax = plt.subplots(nrows=3, sharex=True)
librosa.display.specshow(librosa.power_to_db(melspec,
                                             ref=np.max),
                         x_axis='time', y_axis='mel', ax=ax[0])
ax[0].set(title='Mel spectrogram')
ax[0].label_outer()
ax[1].plot(librosa.times_like(onset_env),
         librosa.util.normalize(onset_env),
         label='Onset strength')
ax[1].plot(librosa.times_like(pulse),
         librosa.util.normalize(pulse),
         label='Predominant local pulse (PLP)')
ax[1].set(title='Uniform tempo prior [30, 300]')
ax[1].label_outer()
ax[2].plot(librosa.times_like(onset_env),
         librosa.util.normalize(onset_env),
         label='Onset strength')
ax[2].plot(librosa.times_like(pulse_lognorm),
         librosa.util.normalize(pulse_lognorm),
         label='Predominant local pulse (PLP)')
ax[2].set(title='Log-normal tempo prior, mean=120', xlim=[5, 20])
ax[2].legend()

tempo, beats = librosa.beat.beat_track(onset_envelope=onset_env)
beats_plp = np.flatnonzero(librosa.util.localmax(pulse))
import matplotlib.pyplot as plt
fig, ax = plt.subplots(nrows=2, sharex=True, sharey=True)
times = librosa.times_like(onset_env, sr=sr)
ax[0].plot(times, librosa.util.normalize(onset_env),
         label='Onset strength')
ax[0].vlines(times[beats], 0, 1, alpha=0.5, color='r',
           linestyle='--', label='Beats')
ax[0].legend()
ax[0].set(title='librosa.beat.beat_track')
ax[0].label_outer()
# Limit the plot to a 15-second window
times = librosa.times_like(pulse, sr=sr)
ax[1].plot(times, librosa.util.normalize(pulse),
         label='PLP')
ax[1].vlines(times[beats_plp], 0, 1, alpha=0.5, color='r',
           linestyle='--', label='PLP Beats')
ax[1].legend()
ax[1].set(title='librosa.beat.plp', xlim=[5, 20])
ax[1].xaxis.set_major_formatter(librosa.display.TimeFormatter())

"""# Estimate the tempo (beats per minute)

"""

# Estimate a static tempo
y, sr = librosa.load(librosa.ex('nutcracker'), duration=30)
onset_env = librosa.onset.onset_strength(y=y, sr=sr)
tempo = librosa.feature.tempo(onset_envelope=onset_env, sr=sr)

# Or a static tempo with a uniform prior instead
import scipy.stats
prior = scipy.stats.uniform(30, 300)  # uniform over 30-300 BPM
utempo = librosa.feature.tempo(onset_envelope=onset_env, sr=sr, prior=prior)

# Or a dynamic tempo
dtempo = librosa.feature.tempo(onset_envelope=onset_env, sr=sr,
                               aggregate=None)

# Dynamic tempo with a proper log-normal prior
prior_lognorm = scipy.stats.lognorm(loc=np.log(120), scale=120, s=1)
dtempo_lognorm = librosa.feature.tempo(onset_envelope=onset_env, sr=sr,
                                       aggregate=None,
                                       prior=prior_lognorm)

import matplotlib.pyplot as plt
# Convert to scalar
tempo = tempo.item()
utempo = utempo.item()
# Compute 2-second windowed autocorrelation
hop_length = 512
ac = librosa.autocorrelate(onset_env, max_size=2 * sr // hop_length)
freqs = librosa.tempo_frequencies(len(ac), sr=sr,
                                  hop_length=hop_length)
# Plot on a BPM axis.  We skip the first (0-lag) bin.
fig, ax = plt.subplots()
ax.semilogx(freqs[1:], librosa.util.normalize(ac)[1:],
             label='Onset autocorrelation', base=2)
ax.axvline(tempo, 0, 1, alpha=0.75, linestyle='--', color='r',
            label='Tempo (default prior): {:.2f} BPM'.format(tempo))
ax.axvline(utempo, 0, 1, alpha=0.75, linestyle=':', color='g',
            label='Tempo (uniform prior): {:.2f} BPM'.format(utempo))
ax.set(xlabel='Tempo (BPM)', title='Static tempo estimation')
ax.grid(True)
ax.legend()

fig, ax = plt.subplots()
tg = librosa.feature.tempogram(onset_envelope=onset_env, sr=sr,
                               hop_length=hop_length)
librosa.display.specshow(tg, x_axis='time', y_axis='tempo', cmap='magma', ax=ax)
ax.plot(librosa.times_like(dtempo), dtempo,
         color='c', linewidth=1.5, label='Tempo estimate (default prior)')
ax.plot(librosa.times_like(dtempo_lognorm), dtempo_lognorm,
         color='c', linewidth=1.5, linestyle='--',
         label='Tempo estimate (lognorm prior)')
ax.set(title='Dynamic tempo estimation')
ax.legend()

"""Compute the tempogram: local autocorrelation of the onset strength envelope."""

# Compute local onset autocorrelation
y, sr = librosa.load(librosa.ex('nutcracker'), duration=30)
hop_length = 512
oenv = librosa.onset.onset_strength(y=y, sr=sr, hop_length=hop_length)
tempogram = librosa.feature.tempogram(onset_envelope=oenv, sr=sr,
                                      hop_length=hop_length)
# Compute global onset autocorrelation
ac_global = librosa.autocorrelate(oenv, max_size=tempogram.shape[0])
ac_global = librosa.util.normalize(ac_global)
# Estimate the global tempo for display purposes
tempo = librosa.feature.tempo(onset_envelope=oenv, sr=sr,
                              hop_length=hop_length)[0]

import matplotlib.pyplot as plt
fig, ax = plt.subplots(nrows=4, figsize=(10, 10))
times = librosa.times_like(oenv, sr=sr, hop_length=hop_length)
ax[0].plot(times, oenv, label='Onset strength')
ax[0].label_outer()
ax[0].legend(frameon=True)
librosa.display.specshow(tempogram, sr=sr, hop_length=hop_length,
                         x_axis='time', y_axis='tempo', cmap='magma',
                         ax=ax[1])
ax[1].axhline(tempo, color='w', linestyle='--', alpha=1,
            label='Estimated tempo={:g}'.format(tempo))
ax[1].legend(loc='upper right')
ax[1].set(title='Tempogram')
x = np.linspace(0, tempogram.shape[0] * float(hop_length) / sr,
                num=tempogram.shape[0])
ax[2].plot(x, np.mean(tempogram, axis=1), label='Mean local autocorrelation')
ax[2].plot(x, ac_global, '--', alpha=0.75, label='Global autocorrelation')
ax[2].set(xlabel='Lag (seconds)')
ax[2].legend(frameon=True)
freqs = librosa.tempo_frequencies(tempogram.shape[0], hop_length=hop_length, sr=sr)
ax[3].semilogx(freqs[1:], np.mean(tempogram[1:], axis=1),
             label='Mean local autocorrelation', base=2)
ax[3].semilogx(freqs[1:], ac_global[1:], '--', alpha=0.75,
             label='Global autocorrelation', base=2)
ax[3].axvline(tempo, color='black', linestyle='--', alpha=.8,
            label='Estimated tempo={:g}'.format(tempo))
ax[3].legend(frameon=True)
ax[3].set(xlabel='BPM')
ax[3].grid(True)

"""#Approximate STFT magnitude from a Mel power spectrogram."""

y, sr = librosa.load(librosa.ex('trumpet'))
S = librosa.util.abs2(librosa.stft(y))
mel_spec = librosa.feature.melspectrogram(S=S, sr=sr)
S_inv = librosa.feature.inverse.mel_to_stft(mel_spec, sr=sr)

import matplotlib.pyplot as plt
fig, ax = plt.subplots(nrows=3, sharex=True, sharey=True)
img = librosa.display.specshow(librosa.amplitude_to_db(S, ref=np.max, top_db=None),
                         y_axis='log', x_axis='time', ax=ax[0])
ax[0].set(title='Original STFT')
ax[0].label_outer()
librosa.display.specshow(librosa.amplitude_to_db(S_inv, ref=np.max, top_db=None),
                         y_axis='log', x_axis='time', ax=ax[1])
ax[1].set(title='Reconstructed STFT')
ax[1].label_outer()
librosa.display.specshow(librosa.amplitude_to_db(np.abs(S_inv - S),
                                                 ref=S.max(), top_db=None),
                         vmax=0, y_axis='log', x_axis='time', cmap='magma', ax=ax[2])
ax[2].set(title='Residual error (dB)')
fig.colorbar(img, ax=ax, format="%+2.f dB")

"""#Invert a mel power spectrogram to audio using Griffin-Lim.


"""

from IPython.display import Audio
y, sr = librosa.load(librosa.ex('trumpet'))
M= librosa.feature.melspectrogram(y=y, sr=sr)

S = librosa.feature.inverse.mel_to_stft(M)
x = librosa.griffinlim(S)

Audio(data=x, rate=sr)

import librosa
import numpy as np
from IPython.display import Audio
import matplotlib.pyplot as plt

y, sr = librosa.load(librosa.ex('libri1'))
mfcc = librosa.feature.mfcc(y=y, sr=sr)
M =librosa.feature.inverse.mfcc_to_mel(mfcc)

S = librosa.feature.inverse.mel_to_stft(M)
x = librosa.griffinlim(S)

Audio(data=x, rate=sr)

Audio(data=y, rate=sr)

y, sr = librosa.load(librosa.ex('libri1'))

M = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128,
                                    fmax=8000)

S = librosa.feature.inverse.mel_to_stft(M)
x = librosa.griffinlim(S)
Audio(data=x, rate=sr)

"""## Speeach Processing - Audio File Creation"""

import numpy as np
import matplotlib.pyplot as plt
from scipy.io import wavfile

f= librosa.ex('libri1')
f

import soundfile as sf

data, samplerate = sf.read(f)
sf.write('libril.wav', data, samplerate)
print(samplerate)

frequency_sampling, audio_signal = wavfile.read('libril.wav')
frequency_sampling,

print('\nSignal shape:', audio_signal.shape)
print('Signal Datatype:', audio_signal.dtype)
print('Signal duration:', round(audio_signal.shape[0] / float(frequency_sampling), 2), 'seconds')

"""## Generating Monotone Audio Signal

"""

import numpy as np
import matplotlib.pyplot as plt
from scipy.io.wavfile import write
from IPython.display import Audio
import matplotlib.pyplot as plt

output_file = 'audio_signal_generated.wav'

duration = 4 # in seconds
frequency_sampling = 44100 # in Hz
frequency_tone = 784
min_val = -4 * np.pi
max_val = 4 * np.pi

t = np.linspace(min_val, max_val, duration * frequency_sampling)
audio_signal = np.sin(2 * np.pi * frequency_tone * t)

write(output_file, frequency_sampling, audio_signal)

frequency_sampling, audio_signal = wavfile.read(output_file)
Audio(data=audio_signal, rate=frequency_sampling)

"""#Create Tone Music"""

!pip install tones

from tones import SINE_WAVE, SAWTOOTH_WAVE
from tones.mixer import Mixer

# Create mixer, set sample rate and amplitude
mixer = Mixer(44100, 0.5)

# Create two monophonic tracks that will play simultaneously, and set
# initial values for note attack, decay and vibrato frequency (these can
# be changed again at any time, see documentation for tones.Mixer
mixer.create_track(0, SAWTOOTH_WAVE, vibrato_frequency=7.0, vibrato_variance=30.0, attack=0.01, decay=0.1)
mixer.create_track(1, SINE_WAVE, attack=0.01, decay=0.1)

# Add a 1-second tone on track 0, slide pitch from c# to f#)
mixer.add_note(0, note='c#', octave=5, duration=3.0, endnote='f#')

# Add a 1-second tone on track 1, slide pitch from f# to g#)
mixer.add_note(1, note='f#', octave=5, duration=3.0, endnote='g#')

# Mix all tracks into a single list of samples and write to .wav file
mixer.write_wav('tones.wav')

# Mix all tracks into a single list of samples scaled from 0.0 to 1.0, and
# return the sample list
samples = mixer.mix()

y, sr = librosa.load('tones.wav')
Audio(data=y, rate=sr)